# tinyGPT
A tiny GPT model inspired by karpathy's [nanoGPT](https://github.com/karpathy/nanoGPT) and OpenAI's GPT-2. This repo deals with pre-training. Currently in this repo 4 different types of architectures are present.  
1. bigram
2. gpt
3. gpt2
4. qwen2.5

to run qwen2 training run this command
```
bash ./runs/run.sh
```
`run.sh` file has all the steps to start pretraining the model. If you want to run manually go through the `./runs/run.sh` to see what are the things needed to manually run the model. To run the training with different datasets and param config comment/uncomment in `run.sh` file.  

run below command to interact with the model
```
python -m tinygpt.out
```

sample generated by model after training e.g.  
```

```

to run the plain gpt training run this command
```
python -m tinygpt.gpt
```

to run the bigram model run below command
```
python -m tinygpt.bigram
```


#### TODOs:
- Finalize project
- Updated readme
- Blog/posts/publish 
- Refactoring, hyperparam tuning, training run