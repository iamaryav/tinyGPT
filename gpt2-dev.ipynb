{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete tinyGPT\n",
    "# Then build and train gpt2\n",
    "# Papers - Attention is all you need\n",
    "# GPT 2/3 paper\n",
    "\n",
    "# Llamac/llama2.c\n",
    "# Cuda \n",
    "\n",
    "#### commands\n",
    "\"\"\"\"\n",
    "To see the gpu stats\n",
    "nvidia-smi \n",
    "# To see al the cpu stats\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to?\n",
    "# Model arcthitecture -> \n",
    "# Data(find and filter) -> \n",
    "# train -> \n",
    "# testing/benchmarks -> \n",
    "# Sample\n",
    "# Some other evaluations and researches like scaling laws, transformer sizing\n",
    "# Configurator\n",
    "# Play with some opensource model also\n",
    "# pretraining | post training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M\n",
    "# sd_hf = model_hf.state_dict()\n",
    "\n",
    "# for k, v in sd_hf.items():\n",
    "#     print(k, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we train model from as small as one to context length\n",
    "# so model will see all kinds of context length and from 1 to length of context(block size)\n",
    "# when predicting the character\n",
    "# batch - for parallel processing\n",
    "# In multidimensional matrix\n",
    "# Each dimension is axis and each axis has index\n",
    "#dim=0 → collapsing rows → gives a summary per column\n",
    "# dim=1 → collapsing columns → gives a summary per row\n",
    "# [a, b, c] = [a][b][c] : same in slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32])\n",
      "torch.Size([4, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6065,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.6065,  0.9519,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.0893, -0.6017, -0.2983,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.1335,  0.0954,  0.2236,  0.0426,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.1996,  0.1531,  0.4165, -0.1471, -0.0293,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.0801,  0.0950,  0.0096,  0.1158, -0.2239, -0.2265,    -inf,\n",
       "             -inf],\n",
       "         [-0.3166,  0.1213,  0.2842, -0.2970, -0.3716, -0.5273,  0.0706,\n",
       "             -inf],\n",
       "         [-0.0362, -0.4743, -0.4011,  0.1258,  0.0207,  0.0619, -0.1340,\n",
       "          -0.0080]],\n",
       "\n",
       "        [[ 0.6808,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.7927,  0.1183,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.6759,  0.0339, -0.1183,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.5092, -0.1803, -0.0262,  0.2142,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.0846,  0.3099, -0.1364, -0.2508, -0.0350,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.2308,  0.0793,  0.0675, -0.1400,  0.0616,  0.0190,    -inf,\n",
       "             -inf],\n",
       "         [ 0.0314, -0.0013, -0.0373,  0.3322,  0.2394, -0.1389,  0.3339,\n",
       "             -inf],\n",
       "         [ 0.3337, -0.1156, -0.2699,  0.1870, -0.0761, -0.2434,  0.2380,\n",
       "          -0.4704]],\n",
       "\n",
       "        [[ 0.0386,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.3283, -0.1845,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.2440, -0.1702,  0.0276,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.1291, -0.2949, -0.0078, -0.3152,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.0485, -0.4650, -0.1344, -0.1220,  0.0846,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.0287,  0.2484, -0.3715,  0.6589, -0.2515,  0.7744,    -inf,\n",
       "             -inf],\n",
       "         [ 0.0507, -0.4889, -0.3530, -0.1098, -0.2920,  0.1701,  0.5203,\n",
       "             -inf],\n",
       "         [ 0.0468, -0.2310,  0.2775, -0.5964, -0.1756, -0.3031,  0.0678,\n",
       "           0.1045]],\n",
       "\n",
       "        [[ 0.0312,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.3076,  0.0415,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.0996, -0.0544,  0.0894,    -inf,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.2682, -0.3629,  0.0116,  0.0302,    -inf,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [ 0.3200,  0.6109,  0.0660, -0.0779,  0.0945,    -inf,    -inf,\n",
       "             -inf],\n",
       "         [-0.0683,  0.3881, -0.2620,  0.2767,  0.2801, -0.0886,    -inf,\n",
       "             -inf],\n",
       "         [-0.0956, -0.2735,  0.2787,  0.2304,  0.3112,  0.3326, -0.0240,\n",
       "             -inf],\n",
       "         [ 0.0466,  0.3654,  0.2238, -0.0803, -0.2409, -0.1853,  0.4194,\n",
       "           0.1505]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B - Batch - parallel input sequence\n",
    "# T - Time(vocab size, sequence length, memory used in prediction, Context size) - position of tokens\n",
    "# c - channel(embedding dimensions, d_model) - Contains feature vector for each token\n",
    "# torch.tril(torch.ones(T, T))\n",
    "# embedding table contains feature vector for each token\n",
    "# each row corresponds to a token and columns feature vector\n",
    "# embedding table dimensions - (vocab_size, Channel)\n",
    "# Each token becomes three vectors: \n",
    "# Query: what this token is looking for?\n",
    "# Key: what this token has to offer\n",
    "# Value: what the information this token contains for sharing to next token i thinks\n",
    "# Encoder model: Takes all the tokens in consideration\n",
    "# Decoder model: Takes only current and past tokens in consideration\n",
    "# Query @ Key = Scores\n",
    "# Scale - Stabilize scores\n",
    "# Softmax(scores) = weights \n",
    "# Weighted average of values - New token representations\n",
    "# Scores: strong positive value - strong match high attention\n",
    "# Near zero: No match - Low attention\n",
    "# Negative number: Disimilar - very low ignored after softmax\n",
    "# Linear Layer is simple matrix multiplication- input @ weight + bias = w @ x + b\n",
    "# Training decides that what query, key and value will contain\n",
    "# Mainly backpropagation and gradient descent this is amazing\n",
    "# embedding dimensions or channel dimensions or feature vector of a token\n",
    "# is broken down in to key, query and vector and we train these three things\n",
    "# and after training these things contains meaning representation of embedding dimensions\n",
    "# query of current token, and key and values of all the past token\n",
    "# Keep the dimensions of k, q, v so dot products should be easy\n",
    "# Mostly same or half\n",
    "# in multi head attention keep the dimension as embd_d // head_size\n",
    "#  The dot product\n",
    "# the dot prodcut in between |A||B|cos(theta)\n",
    "# In Other words: Projection of a on b\n",
    "# IOW: how much A aligns with the B\n",
    "# iow: how much a is in the direction of B\n",
    "# iow: similarity between two vectors\n",
    "# Normalization means: mean 0 and Standard deviation 1\n",
    "# Be award of exploding and vanishing gradient\n",
    "\n",
    "import torch\n",
    "B, T, C = 4, 8, 32 # consider this as stacked sheet of paper\n",
    "x = torch.randn(B, T, C)\n",
    "key = nn.Linear(32, 16)\n",
    "print(key.weight.shape)\n",
    "query = nn.Linear(32, 16)\n",
    "k = key(x) # 4, 8, 16\n",
    "q = query(x) # 4, 8, 16\n",
    "out = (k @ q.transpose(-2, -1)) / k.shape[-1] ** 0.5 # (4, 8, 16) @ (4, 16, 8) -> 4, 8, 8\n",
    "print(out.shape)\n",
    "ones = torch.tril(torch.ones(T, T))\n",
    "out = out.masked_fill(ones == 0, float(\"-inf\"))\n",
    "out\n",
    "# print(key(x).shape) # 4, 8, 32 @ 4, 32, 16 ---> 4, 8, 16 \n",
    "# ex = nn.Linear(3, 5)\n",
    "# print(x2.weight)\n",
    "# x11 = x1(x)\n",
    "# y11 = x2(x)\n",
    "# y11.shape\n",
    "# x11 @ y11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n",
      "tensor([[ 0.6919,  0.2581, -0.1701, -0.3947,  0.0910, -0.0118,  0.2231, -1.2307,\n",
      "         -0.0039, -0.6741,  0.1459, -1.2867, -0.3197,  0.4475,  0.4934, -0.8440],\n",
      "        [ 0.6919,  0.2581, -0.1701, -0.3947,  0.0910, -0.0118,  0.2231, -1.2307,\n",
      "         -0.0039, -0.6741,  0.1459, -1.2867, -0.3197,  0.4475,  0.4934, -0.8440],\n",
      "        [-0.0819, -0.3501, -0.2412,  0.0528,  0.2045,  0.7295, -0.0119, -0.0118,\n",
      "         -0.4419,  0.2094,  1.0352, -0.0915,  0.4527, -0.6376, -0.2764,  0.0615],\n",
      "        [-0.0855, -0.3502, -0.2420,  0.0576,  0.2039,  0.7239, -0.0121, -0.0083,\n",
      "         -0.4364,  0.2113,  1.0321, -0.0880,  0.4440, -0.6383, -0.2797,  0.0601],\n",
      "        [-0.3931, -0.5869, -0.2843,  0.1258,  0.2984,  0.1196,  0.4607,  0.4319,\n",
      "          0.7149, -0.3157, -1.0503,  0.7572,  0.0563, -0.2047, -0.3196, -0.5844],\n",
      "        [ 0.2483,  0.1578, -0.3307, -0.3907,  0.1050, -0.1453,  0.1301, -0.4667,\n",
      "          0.2799, -0.6968, -0.1358, -0.1893, -0.0469,  0.3229,  0.0722, -0.5208],\n",
      "        [-0.2035, -0.3227, -0.2601,  0.2252,  0.1584,  0.4594, -0.0269,  0.0726,\n",
      "         -0.1980,  0.2205,  0.8387,  0.0220,  0.0849, -0.6025, -0.3822, -0.0183],\n",
      "        [ 0.1313,  0.2503, -0.1551, -0.1476, -0.1681,  0.1744, -0.2122, -0.5835,\n",
      "         -0.1893, -0.6129,  0.3363, -0.6102, -0.1151,  0.1699,  0.2327, -0.2174]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "B, T, C = 4, 8, 32\n",
    "vocab_size = 64 # How many tokens?\n",
    "batch_size = 4 # input sequence we will processed in parallel\n",
    "block_size = 8 # Context length, Time dimension\n",
    "embd_d = 32 # Feature vector to represent a token\n",
    "head_size = 16 # size of head\n",
    "dropout = 0.2\n",
    "x = torch.randn(B, T, C) # Input data\n",
    "\n",
    "# One Head Attention Block\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embd_d, head_size, bias=False) # y = x @ wT + b\n",
    "        self.query = nn.Linear(embd_d, head_size, bias=False)\n",
    "        self.value = nn.Linear(embd_d, head_size, bias=False)\n",
    "        # to make lower triangle that will help in weighted average calculation\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size))) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.query(x) # (B, T, head_size)\n",
    "        k = self.key(x) # (B, T, head_size)\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** 0.5 # (B, T, head_size) @ (B, head_size) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\")) # (B, T, T), deactivating next tokens\n",
    "        wei = F.softmax(wei, dim= -1) # (B, T, T)\n",
    "        # helps NN to choose differnet set of Node in different times\n",
    "        # helps to regularize the model so it doesn't overfit\n",
    "        wei = self.dropout(wei) # this is form of regularization\n",
    "        # Weighted aggregation of the values\n",
    "        v = self.value(x) # (B, T, head_size)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n",
    "        return out\n",
    "attention = Head(head_size)\n",
    "y = attention(x)\n",
    "print(y.shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Head attention block\n",
    "# \n",
    "embd_d = 32\n",
    "num_heads = 4\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, embd_d)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # one by one call each head, pass the data and then call the forward method\n",
    "        # then concat the result\n",
    "        out = torch.cat([h(x) for h in self.heads])\n",
    "        # converth output to normal dimensions and apply dropout\n",
    "        out = self.dropout(self.proj(out)) \n",
    "        return out\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embd_d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Linear(embd_d, 4 * embd_d),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4 * embd_d, embd_d),\n",
    "        nn.dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole decoder architecture\n",
    "# \n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(embd_d, num_heads)\n",
    "        head_size = embd_d // num_heads\n",
    "        self.s_attention = MultiHeadAttention(num_heads, head_size)\n",
    "        self.feed_forward = FeedForward(embd_d)\n",
    "        # layer norm normalizes the data with 0 mean and 1 standard deviation\n",
    "        self.ln1 = nn.LayerNorm(embd_d)\n",
    "        self.ln2 = nn.LayerNorm(embd_d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "       # Paper section 3.1\n",
    "       # Adding result back to x is called residual connection or skip connection\n",
    "       # Just add back don't replace it\n",
    "       # Utilize the self attention and add back the result\n",
    "       # it get called the residual connection because it's one part skips the transformation layer\n",
    "       # and gets added in the output\n",
    "       x = x + self.s_attention(self.ln1(x)) # pre norm for better result\n",
    "       # then think for a sec feed forward and back the result\n",
    "       x = x + self.feed_forward(self.ln2(x))\n",
    "       return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final class GPT class\n",
    "n_layer = 6\n",
    "device = \"cuda\"\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Contains the meaning of the token\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embd_d)\n",
    "        # Contains the position vector means this token is at this position and gives the position vector\n",
    "        # helps model understand the position impact of the token\n",
    "        # because it changes the meaning of token based on where they appear\n",
    "        self.position_embedding_table = nn.Embedding(block_size, embd_d)\n",
    "        self.blocks = nn.Sequential(*[Block(embd_d, num_heads) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(embd_d)\n",
    "        self.lm_head = nn.Linear(embd_d, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        # implement _init_weights\n",
    "\n",
    "        def _init_weights(self, module):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    torch.nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "        def forward(self, idx, target=None):\n",
    "            B, T = idx.shape\n",
    "            tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
    "            pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
    "            x = tok_emb + pos_emb # (B, T, C)\n",
    "            x = self.blocks(x) # (B, T, C)\n",
    "            x = self.ln_f(x) # (B, T, C)\n",
    "            logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "            if target is None:\n",
    "                loss = None\n",
    "            else:\n",
    "                B, T, C = logits.shape\n",
    "                logits = logits.view(B*T, C)\n",
    "                targets = targets.view(B*T)\n",
    "                loss= F.cross_entropy(logits, target)\n",
    "            return logits, loss\n",
    "        \n",
    "        def generate(self, idx, max_new_tokens):\n",
    "\n",
    "            for _ in range(max_new_tokens):\n",
    "                idx_cond = idx[:, -block_size:]\n",
    "                logits, loss = self(idx)\n",
    "                # Get the last time step\n",
    "                logits = [:, -1, :] # (B, C)\n",
    "                # calculate the probablity using softmax\n",
    "                prob = F.softmax(logits, dim=-1) # probality using channel dimensions\n",
    "                # because that dimension is the feature vector\n",
    "\n",
    "                idx_next = torch.multinomial(prob, num_samples=1) # (B, 1)\n",
    "\n",
    "                idx = torch.cat((idx, idx_next), dim=1) # (B, T + 1)\n",
    "\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
